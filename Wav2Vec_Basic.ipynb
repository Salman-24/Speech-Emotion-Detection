{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Vec_Basic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_FiLeTkveEd"
      },
      "source": [
        "!pip install transformers==4.3.3\n",
        "!pip install numpy==1.20.1\n",
        "!pip install SoundFile==0.10.3.post1\n",
        "!pip install torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBWxaZ1mF5Ta",
        "outputId": "1d03dae5-ca50-4509-ad4c-995cb44f93bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RhHsR-CTLnd",
        "outputId": "4742c588-10f5-4de5-9c40-1f84933f2833"
      },
      "source": [
        "import sys\n",
        "!unzip -q \"/content/gdrive/MyDrive/final_dataset.zip\" \n",
        "!ls /content/gdrive/My\\ Drive/*.py\n",
        "sys.path.append('/content/gdrive/My Drive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/gdrive/My Drive/data.py'  '/content/gdrive/My Drive/model.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc_h_JRiMv2W"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from data import Data\n",
        "import numpy as np\n",
        "from model import Wav2Vec2\n",
        "import json\n",
        "import os\n",
        "dataset = []\n",
        "label = []\n",
        "if not os.path.exists(\"data.json\"):\n",
        "    data_path = \"/content/Final\"\n",
        "    class_path = os.listdir(data_path)\n",
        "    for ind, i in enumerate(class_path):\n",
        "        temp_path = []\n",
        "        temp_label = []\n",
        "        for j in os.listdir(os.path.join(data_path,i)):\n",
        "            temp_path.append(os.path.join(data_path,i,j))\n",
        "            label.append(ind)\n",
        "        dataset.extend(temp_path)\n",
        "        label.extend(temp_label)\n",
        "    with open('data.json','w') as f:\n",
        "        json.dump({'data':dataset,\n",
        "                'label':label},f)   \n",
        "else:\n",
        "    with open('data.json','r') as f:\n",
        "        temp = json.load(f) \n",
        "        dataset = temp['data']\n",
        "        label = temp['label']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F4OxaGONm5k"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "data = Data(dataset, label)\n",
        "#data = DataLoader(data,batch_size=batch, shuffle=True)\n",
        "batch_size = 64\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_dataloader =  torch.utils.data.DataLoader(data, batch_size=batch_size,sampler=train_sampler)\n",
        "test_dataloader =  torch.utils.data.DataLoader(data, batch_size=batch_size,sampler=valid_sampler)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQy81Ynd7awE"
      },
      "source": [
        "model = Wav2Vec2(n_classes=8)\n",
        "model = model.cuda()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDAmVc87M4t"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    epoch_loss = 0\n",
        "    for X, y in tqdm(dataloader,desc=f\"Epoch:{t}\"):\n",
        "        #X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        X = X.float().cuda()\n",
        "        y = y.squeeze().cuda()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print('Training Loss is %.3f'%(epoch_loss/size))\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4H2YbUi9dxP"
      },
      "source": [
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            #X, y = X.to(device), y.to(device)\n",
        "            X = X.float().cuda()\n",
        "            y = y.squeeze().cuda()\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md9fvNs99fTi"
      },
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkrxXOHaZ2SB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}